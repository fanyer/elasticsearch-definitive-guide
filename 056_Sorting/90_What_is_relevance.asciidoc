[[相关性引言]]
=== 什么是相关性?

我们曾经讲过，默认情况下，返回结果是按相关性倒序排列的。((("relevance", "defined")))
但是什么是相关性？ 相关性如何计算？

每个文档都有相关性评分，用一个相对的正浮点数字段 `_score` 来表示((("score", "calculation of"))) 。 `_score` 的评分越高，相关性越高。


查询语句会为每个文档生成一个 `_score` 字段。评分的计算方式取决于查询类型 ((("fuzzy queries", "calculation of relevence score")))
不同的查询语句用于不同的目的：`fuzzy` 查询会计算与关键词的拼写相似程度，`terms`查询会计算
找到的内容与关键词组成部分匹配的百分比，但是通常我们说的 _relevance_ 是我们用来计算全文本字段的值相对于全文本检索词相似程度的算法。



ElasticSearch的相似度算法((("Term Frequency/Inverse Document Frequency  (TF/IDF) similarity algorithm")))((("similarity algorithms", "Term Frequency/Inverse Document Frequency  (TF/IDF)")))被定义为检索词频率/反向文档频率， _TF/IDF_，包括以下内容：


检索词频率::

   How often does the term appear in the field? The more often, the more
  relevant. A field containing five mentions of the same term is more likely
  to be relevant than a field containing just one mention.

反向文档频率::

   每个检索词在索引中出现的频率？频率越高，相关性越低。
  检索词出现在多数文档中会比出现在少数文档中的权重更低。

Field-length norm::

   How long is the field? The longer it is, the less likely it is that words in
  the field will be relevant. A term appearing in a short `title` field
  carries more weight than the same term appearing in a long `content` field.

Individual ((("field-length norm")))queries may combine the TF/IDF score with other factors
such as the term proximity in phrase queries, or term similarity in
fuzzy queries.

Relevance is not just about full-text search, though. It can equally be applied
to yes/no clauses, where the more clauses that match, the higher the
`_score`.

When multiple query clauses are combined using a compound query((("compound query clauses", "relevance score for results"))) like the
`bool` query, the `_score` from each of these query clauses is combined to
calculate the overall `_score` for the document.

TIP: We have a whole chapter dedicated to relevance calculations and how to
bend them to your will: <<controlling-relevance>>.

[[explain]]
==== Understanding the Score

When debugging a complex query,((("score", "calculation of")))((("relevance scores", "understanding"))) it can be difficult to understand
exactly how a `_score` has been calculated.  Elasticsearch
has the option of producing an _explanation_ with every search result,
by setting the `explain` parameter((("explain parameter"))) to `true`.


[source,js]
--------------------------------------------------
GET /_search?explain <1>
{
   "query"   : { "match" : { "tweet" : "honeymoon" }}
}
--------------------------------------------------
// SENSE: 056_Sorting/90_Explain.json
<1> The `explain` parameter adds an explanation of how the `_score` was
    calculated to every result.

[NOTE]
====
Adding `explain` produces a lot((("explain parameter", "for relevance score calculation"))) of output for every hit, which can look
overwhelming, but it is worth taking the time to understand what it all means.
Don't worry if it doesn't all make sense now; you can refer to this section
when you need it.  We'll work through the output for one `hit` bit by bit.
====

First, we have the metadata that is returned on normal search requests:

[source,js]
--------------------------------------------------
{
    "_index" :      "us",
    "_type" :       "tweet",
    "_id" :         "12",
    "_score" :      0.076713204,
    "_source" :     { ... trimmed ... },
--------------------------------------------------

It adds information about the shard and the node that the document came from,
which is useful to know because term and document frequencies are calculated
per shard, rather than per index:

[source,js]
--------------------------------------------------
    "_shard" :      1,
    "_node" :       "mzIVYCsqSWCG_M_ZffSs9Q",
--------------------------------------------------

Then it provides the `_explanation`. Each ((("explanation of relevance score calculation")))((("description", "of relevance score calculations")))entry contains a  `description`
that tells you what type of calculation is being performed, a `value`
that gives you the result of the calculation, and the `details` of any
subcalculations that were required:

[source,js]
--------------------------------------------------
"_explanation": { <1>
   "description": "weight(tweet:honeymoon in 0)
                  [PerFieldSimilarity], result of:",
   "value":       0.076713204,
   "details": [
      {
         "description": "fieldWeight in 0, product of:",
         "value":       0.076713204,
         "details": [
            {  <2>
               "description": "tf(freq=1.0), with freq of:",
               "value":       1,
               "details": [
                  {
                     "description": "termFreq=1.0",
                     "value":       1
                  }
               ]
            },
            { <3>
               "description": "idf(docFreq=1, maxDocs=1)",
               "value":       0.30685282
            },
            { <4>
               "description": "fieldNorm(doc=0)",
               "value":        0.25,
            }
         ]
      }
   ]
}
--------------------------------------------------
<1> `honeymoon` 相关性评分计算的总结
<2> 检索词频率
<3> 反向文档频率
<4> 字段长度准则

警告: 输出 `explain` 结果代价是十分昂贵的，它只能用作调试工具((("explain parameter", "overhead of using"))) 。
千万不要用于生产环境。


第一部分是关于计算的总结。告诉了我们 `"honeymoon"` 在 `tweet`字段中的检索词频率/反向文档频率或 TF/IDF，
（这里的文档 `0` 是一个内部的ID，跟我们没有关系，可以忽略。）

然后解释了计算的权重是如何计算出来的：

Term frequency::

   How many times did the term `honeymoon` appear in the `tweet` field in
   this document?

Inverse document frequency::

   How many times did the term `honeymoon` appear in the `tweet` field
   of all documents in the index?

Field-length norm::

   How long is the `tweet` field in this document? The longer the field,
   the smaller this number.

Explanations for more-complicated queries can appear to be very complex, but
really they just contain more of the same calculations that appear in the
preceding example. This information can be invaluable for debugging why search
results appear in the order that they do.

[TIP]
==================================================================
The output from `explain` can be difficult to read in JSON, but it is easier
when it is formatted as YAML.((("explain parameter", "formatting output in YAML")))((("YAML, formatting explain output in"))) Just add `format=yaml` to the query string.
==================================================================


[[explain-api]]
==== Understanding Why a Document Matched

While the `explain` option adds an explanation for every result, you can use
the `explain` API to understand why one particular document matched or, more
important, why it _didn't_ match.((("relevance", "understanding why a document matched")))((("explain API, understanding why a document matched")))

The path for the request is `/index/type/id/_explain`, as in the following:

[source,js]
--------------------------------------------------
GET /us/tweet/12/_explain
{
   "query" : {
      "bool" : {
         "filter" : { "term" :  { "user_id" : 2           }},
         "must" :  { "match" : { "tweet" :   "honeymoon" }}
      }
   }
}
--------------------------------------------------
// SENSE: 056_Sorting/90_Explain_API.json

Along with the full explanation((("description", "of why a document didn&#x27;t match"))) that we saw previously, we also now have a
`description` element, which tells us this:


[source,js]
--------------------------------------------------
"failure to match filter: cache(user_id:[2 TO 2])"
--------------------------------------------------

也就是说我们的 `user_id` 过滤子句使该文档不能匹配到。

